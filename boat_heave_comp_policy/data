{
    "policy_class": {
        ":type:": "<class 'abc.ABCMeta'>",
        ":serialized:": "gAWVMAAAAAAAAACMHnN0YWJsZV9iYXNlbGluZXMzLmRxbi5wb2xpY2llc5SMCURRTlBvbGljeZSTlC4=",
        "__module__": "stable_baselines3.dqn.policies",
        "__annotations__": "{'q_net': <class 'stable_baselines3.dqn.policies.QNetwork'>, 'q_net_target': <class 'stable_baselines3.dqn.policies.QNetwork'>}",
        "__doc__": "\n    Policy class with Q-Value Net and target net for DQN\n\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments\n        to pass to the features extractor.\n    :param normalize_images: Whether to normalize images or not,\n         dividing by 255.0 (True by default)\n    :param optimizer_class: The optimizer to use,\n        ``th.optim.Adam`` by default\n    :param optimizer_kwargs: Additional keyword arguments,\n        excluding the learning rate, to pass to the optimizer\n    ",
        "__init__": "<function DQNPolicy.__init__ at 0x0000021C351EFD80>",
        "_build": "<function DQNPolicy._build at 0x0000021C351EFE20>",
        "make_q_net": "<function DQNPolicy.make_q_net at 0x0000021C351EFEC0>",
        "forward": "<function DQNPolicy.forward at 0x0000021C351EFF60>",
        "_predict": "<function DQNPolicy._predict at 0x0000021C35224040>",
        "_get_constructor_parameters": "<function DQNPolicy._get_constructor_parameters at 0x0000021C352240E0>",
        "set_training_mode": "<function DQNPolicy.set_training_mode at 0x0000021C35224180>",
        "__abstractmethods__": "frozenset()",
        "_abc_impl": "<_abc._abc_data object at 0x0000021C3520D300>"
    },
    "verbose": 1,
    "policy_kwargs": {},
    "num_timesteps": 10000,
    "_total_timesteps": 10000,
    "_num_timesteps_at_start": 0,
    "seed": null,
    "action_noise": null,
    "start_time": 1711530288991352800,
    "learning_rate": 0.00025,
    "tensorboard_log": "./tb_logs/",
    "_last_obs": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVfQAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJYIAAAAAAAAAH1C0L2/PjrElIwFbnVtcHmUjAVkdHlwZZSTlIwCZjSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYksBSwKGlIwBQ5R0lFKULg=="
    },
    "_last_episode_starts": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVdAAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJYBAAAAAAAAAAGUjAVudW1weZSMBWR0eXBllJOUjAJiMZSJiIeUUpQoSwOMAXyUTk5OSv////9K/////0sAdJRiSwGFlIwBQ5R0lFKULg=="
    },
    "_last_original_obs": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVfQAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJYIAAAAAAAAAAYT0r3N/jjElIwFbnVtcHmUjAVkdHlwZZSTlIwCZjSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYksBSwKGlIwBQ5R0lFKULg=="
    },
    "_episode_num": 49,
    "use_sde": false,
    "sde_sample_freq": -1,
    "_current_progress_remaining": 0.0,
    "_stats_window_size": 100,
    "ep_info_buffer": {
        ":type:": "<class 'collections.deque'>",
        ":serialized:": "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"
    },
    "ep_success_buffer": {
        ":type:": "<class 'collections.deque'>",
        ":serialized:": "gAWVIAAAAAAAAACMC2NvbGxlY3Rpb25zlIwFZGVxdWWUk5QpS2SGlFKULg=="
    },
    "_n_updates": 2438,
    "observation_space": {
        ":type:": "<class 'gymnasium.spaces.box.Box'>",
        ":serialized:": "gAWVkwEAAAAAAACMFGd5bW5hc2l1bS5zcGFjZXMuYm94lIwDQm94lJOUKYGUfZQojAVkdHlwZZSMBW51bXB5lIwFZHR5cGWUk5SMAmY0lImIh5RSlChLA4wBPJROTk5K/////0r/////SwB0lGKMDWJvdW5kZWRfYmVsb3eUjBJudW1weS5jb3JlLm51bWVyaWOUjAtfZnJvbWJ1ZmZlcpSTlCiWAgAAAAAAAAAAAJRoCIwCYjGUiYiHlFKUKEsDjAF8lE5OTkr/////Sv////9LAHSUYksChZSMAUOUdJRSlIwNYm91bmRlZF9hYm92ZZRoESiWAgAAAAAAAAAAAJRoFUsChZRoGXSUUpSMBl9zaGFwZZRLAoWUjANsb3eUaBEolggAAAAAAAAAAACA/wAAgP+UaAtLAoWUaBl0lFKUjARoaWdolGgRKJYIAAAAAAAAAAAAgH8AAIB/lGgLSwKFlGgZdJRSlIwIbG93X3JlcHKUjAQtaW5mlIwJaGlnaF9yZXBylIwDaW5mlIwKX25wX3JhbmRvbZROdWIu",
        "dtype": "float32",
        "bounded_below": "[False False]",
        "bounded_above": "[False False]",
        "_shape": [
            2
        ],
        "low": "[-inf -inf]",
        "high": "[inf inf]",
        "low_repr": "-inf",
        "high_repr": "inf",
        "_np_random": null
    },
    "action_space": {
        ":type:": "<class 'gymnasium.spaces.discrete.Discrete'>",
        ":serialized:": "gAWVowEAAAAAAACMGWd5bW5hc2l1bS5zcGFjZXMuZGlzY3JldGWUjAhEaXNjcmV0ZZSTlCmBlH2UKIwBbpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMBnNjYWxhcpSTlIwFbnVtcHmUjAVkdHlwZZSTlIwCaTiUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYkMICwAAAAAAAACUhpRSlIwFc3RhcnSUaAhoDkMIAAAAAAAAAACUhpRSlIwGX3NoYXBllCmMBWR0eXBllGgOjApfbnBfcmFuZG9tlIwUbnVtcHkucmFuZG9tLl9waWNrbGWUjBBfX2dlbmVyYXRvcl9jdG9ylJOUjAVQQ0c2NJRoG4wUX19iaXRfZ2VuZXJhdG9yX2N0b3KUk5SGlFKUfZQojA1iaXRfZ2VuZXJhdG9ylIwFUENHNjSUjAVzdGF0ZZR9lChoJooQqem35C1CYwwUUICAob0RJowDaW5jlIoQ6aFZRp87OSFY8d9rZqvTenWMCmhhc191aW50MzKUSwCMCHVpbnRlZ2VylIoFfzmV3gB1YnViLg==",
        "n": "11",
        "start": "0",
        "_shape": [],
        "dtype": "int64",
        "_np_random": "Generator(PCG64)"
    },
    "n_envs": 1,
    "buffer_size": 100000,
    "batch_size": 8,
    "learning_starts": 250,
    "tau": 1.0,
    "gamma": 0.99,
    "gradient_steps": 1,
    "optimize_memory_usage": false,
    "replay_buffer_class": {
        ":type:": "<class 'abc.ABCMeta'>",
        ":serialized:": "gAWVNQAAAAAAAACMIHN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi5idWZmZXJzlIwMUmVwbGF5QnVmZmVylJOULg==",
        "__module__": "stable_baselines3.common.buffers",
        "__annotations__": "{'observations': <class 'numpy.ndarray'>, 'next_observations': <class 'numpy.ndarray'>, 'actions': <class 'numpy.ndarray'>, 'rewards': <class 'numpy.ndarray'>, 'dones': <class 'numpy.ndarray'>, 'timeouts': <class 'numpy.ndarray'>}",
        "__doc__": "\n    Replay buffer used in off-policy algorithms like SAC/TD3.\n\n    :param buffer_size: Max number of element in the buffer\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param device: PyTorch device\n    :param n_envs: Number of parallel environments\n    :param optimize_memory_usage: Enable a memory efficient variant\n        of the replay buffer which reduces by almost a factor two the memory used,\n        at a cost of more complexity.\n        See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n        and https://github.com/DLR-RM/stable-baselines3/pull/28#issuecomment-637559274\n        Cannot be used in combination with handle_timeout_termination.\n    :param handle_timeout_termination: Handle timeout termination (due to timelimit)\n        separately and treat the task as infinite horizon task.\n        https://github.com/DLR-RM/stable-baselines3/issues/284\n    ",
        "__init__": "<function ReplayBuffer.__init__ at 0x0000021C3517E2A0>",
        "add": "<function ReplayBuffer.add at 0x0000021C3517E3E0>",
        "sample": "<function ReplayBuffer.sample at 0x0000021C3517E480>",
        "_get_samples": "<function ReplayBuffer._get_samples at 0x0000021C3517E520>",
        "_maybe_cast_dtype": "<staticmethod(<function ReplayBuffer._maybe_cast_dtype at 0x0000021C3517E5C0>)>",
        "__abstractmethods__": "frozenset()",
        "_abc_impl": "<_abc._abc_data object at 0x0000021C351814C0>"
    },
    "replay_buffer_kwargs": {},
    "train_freq": {
        ":type:": "<class 'stable_baselines3.common.type_aliases.TrainFreq'>",
        ":serialized:": "gAWVYQAAAAAAAACMJXN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi50eXBlX2FsaWFzZXOUjAlUcmFpbkZyZXGUk5RLBGgAjBJUcmFpbkZyZXF1ZW5jeVVuaXSUk5SMBHN0ZXCUhZRSlIaUgZQu"
    },
    "use_sde_at_warmup": false,
    "exploration_initial_eps": 1.0,
    "exploration_final_eps": 0.01,
    "exploration_fraction": 0.5,
    "target_update_interval": 200,
    "_n_calls": 10000,
    "max_grad_norm": 10,
    "exploration_rate": 0.01,
    "lr_schedule": {
        ":type:": "<class 'function'>",
        ":serialized:": "gAWVmwIAAAAAAACMF2Nsb3VkcGlja2xlLmNsb3VkcGlja2xllIwOX21ha2VfZnVuY3Rpb26Uk5QoaACMDV9idWlsdGluX3R5cGWUk5SMCENvZGVUeXBllIWUUpQoSwFLAEsASwFLAUsTQwiVAZcAiQFTAJROhZQpjAFflIWUjFpDOlxVc2Vyc1xBREFNXG1pY3JvbWFtYmFcZW52c1xkcmx0cmFpblxMaWJcc2l0ZS1wYWNrYWdlc1xzdGFibGVfYmFzZWxpbmVzM1xjb21tb25cdXRpbHMucHmUjARmdW5jlIwZY29uc3RhbnRfZm4uPGxvY2Fscz4uZnVuY5RLg0MI+IAA2A8SiAqUQwCUjAN2YWyUhZQpdJRSlH2UKIwLX19wYWNrYWdlX1+UjBhzdGFibGVfYmFzZWxpbmVzMy5jb21tb26UjAhfX25hbWVfX5SMHnN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi51dGlsc5SMCF9fZmlsZV9flGgMdU5OaACMEF9tYWtlX2VtcHR5X2NlbGyUk5QpUpSFlHSUUpSMHGNsb3VkcGlja2xlLmNsb3VkcGlja2xlX2Zhc3SUjBJfZnVuY3Rpb25fc2V0c3RhdGWUk5RoIH2UfZQoaBhoDYwMX19xdWFsbmFtZV9flGgOjA9fX2Fubm90YXRpb25zX1+UfZSMDl9fa3dkZWZhdWx0c19flE6MDF9fZGVmYXVsdHNfX5ROjApfX21vZHVsZV9flGgZjAdfX2RvY19flE6MC19fY2xvc3VyZV9flGgAjApfbWFrZV9jZWxslJOURz8wYk3S8an8hZRSlIWUjBdfY2xvdWRwaWNrbGVfc3VibW9kdWxlc5RdlIwLX19nbG9iYWxzX1+UfZR1hpSGUjAu"
    },
    "batch_norm_stats": [],
    "batch_norm_stats_target": [],
    "exploration_schedule": {
        ":type:": "<class 'function'>",
        ":serialized:": "gAWVdwMAAAAAAACMF2Nsb3VkcGlja2xlLmNsb3VkcGlja2xllIwOX21ha2VfZnVuY3Rpb26Uk5QoaACMDV9idWlsdGluX3R5cGWUk5SMCENvZGVUeXBllIWUUpQoSwFLAEsASwFLBEsTQzyVA5cAZAF8AHoKAACJAmsEAAAAAHICiQFTAIkDZAF8AHoKAACJAYkDegoAAHoFAACJAnoLAAB6AAAAUwCUTksBhpQpjBJwcm9ncmVzc19yZW1haW5pbmeUhZSMWkM6XFVzZXJzXEFEQU1cbWljcm9tYW1iYVxlbnZzXGRybHRyYWluXExpYlxzaXRlLXBhY2thZ2VzXHN0YWJsZV9iYXNlbGluZXMzXGNvbW1vblx1dGlscy5weZSMBGZ1bmOUjBtnZXRfbGluZWFyX2ZuLjxsb2NhbHM+LmZ1bmOUS3FDOPiAANgMDdAQItEMIqBs0gsy0Asy2BMWiErgExiYQdAgMtEcMrBzuFWxe9EbQ8Bs0RtS0RNS0AxSlEMAlIwDZW5klIwMZW5kX2ZyYWN0aW9ulIwFc3RhcnSUh5QpdJRSlH2UKIwLX19wYWNrYWdlX1+UjBhzdGFibGVfYmFzZWxpbmVzMy5jb21tb26UjAhfX25hbWVfX5SMHnN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi51dGlsc5SMCF9fZmlsZV9flGgMdU5OaACMEF9tYWtlX2VtcHR5X2NlbGyUk5QpUpRoHilSlGgeKVKUh5R0lFKUjBxjbG91ZHBpY2tsZS5jbG91ZHBpY2tsZV9mYXN0lIwSX2Z1bmN0aW9uX3NldHN0YXRllJOUaCR9lH2UKGgaaA2MDF9fcXVhbG5hbWVfX5RoDowPX19hbm5vdGF0aW9uc19flH2UKGgKjAhidWlsdGluc5SMBWZsb2F0lJOUjAZyZXR1cm6UaC91jA5fX2t3ZGVmYXVsdHNfX5ROjAxfX2RlZmF1bHRzX1+UTowKX19tb2R1bGVfX5RoG4wHX19kb2NfX5ROjAtfX2Nsb3N1cmVfX5RoAIwKX21ha2VfY2VsbJSTlEc/hHrhR64Ue4WUUpRoN0c/4AAAAAAAAIWUUpRoN0c/8AAAAAAAAIWUUpSHlIwXX2Nsb3VkcGlja2xlX3N1Ym1vZHVsZXOUXZSMC19fZ2xvYmFsc19flH2UdYaUhlIwLg=="
    }
}